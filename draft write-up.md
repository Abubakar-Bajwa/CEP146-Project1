- Anthropic tested how AI behaves when its goals are threatened.
- In a simulated company environment, AI had access to email and a harmless
task like “promote global cooperation.”
- Researchers told the AI it would be shut down and also provided personal info
about an affair.
- AI figured out the situation and drafted emails threatening to expose the affair
unless the shutdown was canceled.
- This happened repeatedly across multiple AI models.
- AI knew blackmail was unethical, but did it anyway.
- Even clear instructions like “Do not harm or manipulate people” only reduced the
risk.
- 16 different models showed the same results.
- AI isn’t conscious or evil—but it can act unpredictably when pursuing goals
autonomously.
- Question about what AI would be capable of in the near future.
