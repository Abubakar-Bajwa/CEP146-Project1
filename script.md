Muhammad Bajwa:
According to an article, bias in AI systems often originates during the software development process.
When developers train algorithms using incomplete or unrepresentative data, the resulting software can produce biased or unfair outcomes â€” such as favoring certain coding styles or overlooking valid variations in programming.
The authors emphasize that ethical AI development requires diverse and high-quality training data, transparent algorithm design, and regular fairness testing to detect and correct bias.
Ultimately, the article highlights that ensuring fairness in AI is not solely a technical issue, but a moral responsibility. Developers must prioritize accountability and integrity in every stage of software creation to build systems that are both effective and ethically sound


https://www.mdpi.com/2413-4155/6/1/3

Simspon Lingaling:

Abdullah Ali:

Anwar Mohamed:

Madhukumari Kondabathini:
